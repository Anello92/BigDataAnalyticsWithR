---
title: "Untitled"
output:
  html_document:
    df_print: paged
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

# Arvore de decisão em R

O processo:
1. Definir problema de negócio
2. Coletar dados
3. Análise Exploratória
4. Manipulação de Dados - Munging
5. Treinar modelos
6. Avaliar modelo
7. Otimizarm modelo


## Existem diversos pacotes para árvores de decisão em R. Usaremos aqui o rpart.
```{r}
install.packages('rpart')
library(rpart)
```

-----------------------------------------------------------------------------------------

## Vamos utilizar um dataset que é disponibilizado junto com o pacote rpart
```{r}
str(kyphosis)
```

```{r}
head(kyphosis, n =1)
```

```{r}
View(kyphosis)
# kyphosis é um fator com níveis ausente|presente indicando se a deformação está presente pós operação 
```

```{r}
?kyphosis 
```
-----------------------------------------------------------------------------------------

##Depois de explorar o dataset, cria o Modelo de Árvore de Decisão
```{r}
?rpart # função para criação de modelo de árvores de decisão, tanto para regressão como classificação 
```

```{r}
arvore <- rpart(Kyphosis ~ .,       # relacionando a deformação com todas as variáveis
                method = 'class',   # método classificação para um PROBLEMA de classificação
                data = kyphosis)    # dataset


class(arvore) # modelo classe "rpart
```

```{r}
arvore # imprimir modelo criado - este modo de impressão NÃO É VISUAL
```

-----------------------------------------------------------------------------------------

## Resumo completo de Árvore de Classificação com printcp() -
```{r}
printcp(arvore)

#variáveis usadas: Age | Start
#erro do modelo árvore = 0.2098
#qtde observações = 81

```

##  Visualizar a Árvore de maneira gráfica e passar a camada gráfica
```{r}
plot(arvore, uniform = TRUE, main = "Arvore de Decisao em R")
text(arvore, use.n = TRUE, all = TRUE)

```


## Este outro pacote faz a visualização ficar mais legível
```{r}
install.packages('rpart.plot')
library(rpart.plot)
prp(arvore)
```

## Dataset iris - observações de 3 espécies de flores. Para cada flor, 4 medidas sao usadas
```{r}
library(datasets)
```

```{r}
head(iris, n = 1)
```

```{r}
View(iris)
```

## Análise exploratória de dados com ggplot2
```{r}
install.packages("ggplot2")
library(ggplot2)
```

## Nitidamente, o conjunto possui grupos com característcas similares
```{r}
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point(size = 3) # pontos de tamanho 3
```

## Agora usarmeos o K-Means para tentar agrupar os dados em clusters
```{r}
help(kmeans) # algoritmo mais famoso de clusterização 
```

## Usar a função kmeans(), criar um modelo de clustering (aprendizagem não supervisionada).
## Temos 3 clusters, 5 colunas, usamos apenas as 4 primeiras
```{r}
irisCluster <- kmeans(iris[, 1:4], #conjunto de dados e slicing das 4 colunas
                      3,           #indicar número de clusters desejado
                      nstart = 20) #quantidade de números randômicos

irisCluster
# A saída é um vetor de clusterização 
```


## Aplicar a tabulação à saída do modelo
### Ao dividir alguns dos dados, apesar de terem carac. diferentes, ficaram no mesmo cluster. 
```{r}
table(irisCluster$cluster, iris$Species)
```

## Visualizando os clusters graficamente
```{r}
install.packages("cluster")
library(cluster)
#help(clusplot)
```

## Plot passando dataset iris e cluster criado
## Modelo retorna os pontos de dados que representam cada planta por padrão, similaridade

#1.Detectar padrões e similaridades (aprnedizagem não supervisionada)
#2.divir dados em grupos, 
#3.estudar cada grupo de maneira individual (aprendizagem supervisionada)
```{r} 
clusplot(iris, irisCluster$cluster, color = TRUE, shade = TRUE, labels = 0, lines = 0 )
```






